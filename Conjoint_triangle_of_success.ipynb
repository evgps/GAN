{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# coding: utf-8\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\" # change 0  with whatever card is available\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "import numpy as np\n",
    "# from trainVAE_D import trainVAE_D\n",
    "# coding: utf-8\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import random \n",
    "from Constant import Constants\n",
    "from load_data import StyleData\n",
    "from PreTrainDs import indexData2variable\n",
    "import time\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torch.load('./Model/Ds.pkl').cuda()\n",
    "ds_emb = torch.load('./Model/Ds_emb.pkl').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/trainDataOfIndex.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_path = './Model/gan2.pkl'\n",
    "style_path = './data/style.npy'\n",
    "epoches = 30\n",
    "batch_size = 1\n",
    "pretrainD = True\n",
    "\n",
    "# trainVAE_D(epoches, batch_size, train_data, ds, ds_emb,  gan_path, style_path,pretrainD)\n",
    "\n",
    "print (\"finished trainning.......................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = np.load(style_path)\n",
    "ind_sentense = data[0][0]\n",
    "sentense = ' '.join([style_data[1][x] for x in ind_sentense])\n",
    "sentense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unembed(x1, W_normalized, style_data):\n",
    "    #calculate cosine similarity\n",
    "    x1_normalized = x1.div(x1.norm(p = 2, dim=1, keepdim=True))\n",
    "    emb_distances = torch.mm(x1_normalized, W_normalized.t())\n",
    "    token_ids = torch.argmax(emb_distances, dim=1).cpu().numpy()\n",
    "    sentense = ' '.join([style_data[1][x] for x in token_ids])\n",
    "    return (token_ids, sentense)\n",
    "\n",
    "def ind_to_words(ind_sent, style_data):\n",
    "    return (' '.join([style_data[1][x] for x in ind_sent]))\n",
    "\n",
    "def onehot_to_words(onehot, style_data):\n",
    "    ind_sent = onehot.argmax(dim=1).cpu().numpy()\n",
    "    print(onehot)\n",
    "    print(ind_sent)\n",
    "    return (' '.join([style_data[1][x] for x in ind_sent]))\n",
    "                \n",
    "def build2pairs(train_data):\n",
    "    data = []\n",
    "    for i in range(min( len(train_data[0]), len(train_data[1]) )):\n",
    "           data.append([train_data[0][i], train_data[1][i]])\n",
    "    return data\n",
    "\n",
    "def shuffleData(train_data):\n",
    "    \"\"\"\n",
    "    this function don't need to return any value and the list is changed inplace\n",
    "    \"\"\"\n",
    "    if len(train_data) == 2:\n",
    "        random.shuffle(train_data[0])\n",
    "        random.shuffle(train_data[1])\n",
    "    else:\n",
    "        random.shuffle(train_data)\n",
    "\n",
    "        \n",
    "def get_d_acc(gan, train_data):\n",
    "    \n",
    "    acc = 0\n",
    "    min_len = len(train_data)/100\n",
    "    train_data = train_data[:min_len]\n",
    "    for i in range(min_len):\n",
    "        dic = gan(train_data[i][0],train_data[i][1],Ez_train=False,Ey_train=False,G_train=False,\n",
    "                              Lcyc=False, Lrec=False, Ldis = False)\n",
    "        if dic['D_x1_wl'].topk(1)[1].cpu().data.numpy() == 0:\n",
    "            acc += 1\n",
    "        if dic['D_x2_hat'].topk(1)[1].cpu().data.numpy() == 1:\n",
    "            acc += 1\n",
    "    \n",
    "    print((\"acc:\\t\\t %.4f\" % (acc/(min_len*2.0))))\n",
    "    return acc/(min_len*2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = torch.load(gan_path)\n",
    "gan = gan.cuda()\n",
    "\n",
    "W = gan.embedding.embedding.weight\n",
    "W_normalized = W.div(W.norm(p = 2, dim=1, keepdim=True))\n",
    "\n",
    "style = StyleData()\n",
    "style.load(style_path)\n",
    "const = Constants(style.n_words)\n",
    "optimizer = optim.Adam(gan.parameters(),lr=const.Lr)\n",
    "lamda1 = 1\n",
    "lamda2 = 1\n",
    "lamda3 = 3\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "# init the state of some model\n",
    "ds.train(False)\n",
    "ds_emb.train(False)\n",
    "\n",
    "train_data = indexData2variable(data)\n",
    "train_data = build2pairs(train_data)\n",
    "# get list([Var(data[0,i]), Var(data[1,i])])\n",
    "stime = time.time()        \n",
    "count = 0\n",
    "while count < len(train_data):\n",
    "    tempdata = train_data[count:count+batch_size]\n",
    "\n",
    "    if tempdata == []:\n",
    "        break\n",
    "\n",
    "    count += batch_size\n",
    "    optimizer.zero_grad()\n",
    "    Lrec = 0\n",
    "    Lcyc = 0\n",
    "    Ldis = 0\n",
    "    Ladv = 0\n",
    "\n",
    "    Loss = 0\n",
    "\n",
    "# before we let the D lead the gradient the D model must be strong enough\n",
    "    for seqs in tempdata:\n",
    "        seqs[0] = seqs[0].cuda()\n",
    "        seqs[1] = seqs[1].cuda()\n",
    "        print(seqs[0])\n",
    "        dic = gan(seqs[0],seqs[1],D_train=False)\n",
    "        print(unembed(dic['x1'], W_normalized, style_data)[1])\n",
    "        print(onehot_to_words(dic['x1_hat'], style_data))\n",
    "        print(onehot_to_words(dic['x1_bar'], style_data))\n",
    "\n",
    "etime = time.time()\n",
    "print((\"cost time \\t%.2f mins\" % ((etime - stime)/60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
